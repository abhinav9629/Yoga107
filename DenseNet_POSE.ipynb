{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DenseNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBEQKu45CEHLtUmN4wLv+R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinav9629/Yoga107/blob/main/DenseNet_POSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udt4dZti2Th3",
        "outputId": "4cdd78b0-aeba-4d73-ac07-f980287a4f04"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMHzVEgW3CJE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZKYpI4_2pwR"
      },
      "source": [
        "dataset_path = '/content/drive/MyDrive/DATASETS/YogaDataset/poseDataset'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aConhl3N25ZA",
        "outputId": "7842df6d-e049-4024-eec7-24bb734a06ed"
      },
      "source": [
        "labels = []\n",
        "for label in os.listdir(dataset_path):\n",
        "  labels.append(label)\n",
        "print(len(labels))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRDSrc6j3hhU",
        "outputId": "2ae1e45c-c050-4105-dea6-e84a309fac38"
      },
      "source": [
        "train_set=[]\n",
        "test_set=[]\n",
        "count=0\n",
        "for files in os.listdir(dataset_path):\n",
        "    t=0\n",
        "    path=os.path.join(dataset_path,files)\n",
        "    for img in os.listdir(path):\n",
        "        image=load_img(os.path.join(path,img), grayscale=False, color_mode='rgb', target_size=(128,128))\n",
        "        image=img_to_array(image)\n",
        "        image=image/255.0\n",
        "        if t<60:\n",
        "            train_set.append([image,count])\n",
        "        else:\n",
        "            test_set.append([image,count])\n",
        "        t=t+1\n",
        "    count=count+1\n",
        "    print(count,end=\" \")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "555bInxbHf4d"
      },
      "source": [
        "train,labels0 = zip(*train_set)\n",
        "test,testlabels0 = zip(*test_set)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP8erbwIH3WP"
      },
      "source": [
        "labels1 = to_categorical(labels0)\n",
        "label = np.array(labels1) "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1FZRLxISwy"
      },
      "source": [
        "train = np.array(train)\n",
        "test = np.array(test)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9au8PFSOSwRA"
      },
      "source": [
        "trainx,testx,trainy,testy=train_test_split(train,label,test_size=0.2,random_state=44)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyLglpFWpgkl"
      },
      "source": [
        "datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=20,zoom_range=0.2,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.1,fill_mode=\"nearest\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww6yd3ZYpvd1"
      },
      "source": [
        "#pretrained_model = tf.keras.applications.DenseNet201(input_shape=(40,40,3),include_top=False,weights='imagenet',pooling='avg')\n",
        "#pretrained_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM78oKBf92Tg"
      },
      "source": [
        "#pretrained_model = keras.applications.ResNet101(input_shape=(40,40,3),include_top=False,weights='imagenet',pooling=\"avg\")\n",
        "#pretrained_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhhYp6QTr-aM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e042ee77-3343-46cb-f7f4-c19d5a951344"
      },
      "source": [
        "'''\n",
        "inputs = pretrained_model.input\n",
        "x = keras.layers.Dense(512, activation='relu')(pretrained_model.output)\n",
        "x = keras.layers.Dropout(0.3)(x)\n",
        "#x = keras.layers.Dense(256,activation='relu')(x)\n",
        "#x = keras.layers.Dropout(0.3)(x)\n",
        "outputs = tf.keras.layers.Dense(107, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ninputs = pretrained_model.input\\nx = keras.layers.Dense(512, activation='relu')(pretrained_model.output)\\nx = keras.layers.Dropout(0.3)(x)\\n#x = keras.layers.Dense(256,activation='relu')(x)\\n#x = keras.layers.Dropout(0.3)(x)\\noutputs = tf.keras.layers.Dense(107, activation='softmax')(x)\\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Igjglc0YQ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "9d46d3e6-6ad1-4fc6-cec8-21121aef60b0"
      },
      "source": [
        "#CUSTOM MODEL 1\n",
        "'''\n",
        "model = keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding = 'Same', input_shape=(40, 40, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    #tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n",
        "    #tf.keras.layers.MaxPooling2D(2,2),\n",
        "    #tf.keras.layers.Dropout(0.25),\n",
        "    #tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n",
        "    #tf.keras.layers.MaxPooling2D(2,2),\n",
        "    #tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(107, activation='softmax')\n",
        "])\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nmodel = keras.Sequential([\\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding = 'Same', input_shape=(40, 40, 3)),\\n    tf.keras.layers.MaxPooling2D(2, 2),\\n    tf.keras.layers.Dropout(0.25),\\n    #tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\\n    #tf.keras.layers.MaxPooling2D(2,2),\\n    #tf.keras.layers.Dropout(0.25),\\n    #tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\\n    #tf.keras.layers.MaxPooling2D(2,2),\\n    #tf.keras.layers.Dropout(0.25),\\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\\n    tf.keras.layers.MaxPooling2D(2,2),\\n    tf.keras.layers.Dropout(0.25),\\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding = 'Same'),\\n    tf.keras.layers.MaxPooling2D(2,2),\\n    tf.keras.layers.Dropout(0.25),\\n    tf.keras.layers.Flatten(),\\n    tf.keras.layers.Dense(1024, activation='relu'),\\n    tf.keras.layers.Dropout(0.5),\\n    tf.keras.layers.Dense(107, activation='softmax')\\n])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6BLmxGmrxkO"
      },
      "source": [
        "#CUSTOM MODEL 2\n",
        "model = keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu',padding = 'Same', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(107, activation='softmax')\n",
        "])\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHoVvZKCst_A"
      },
      "source": [
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT944ryWhbQf"
      },
      "source": [
        "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(MyThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        accuracy = logs[\"val_accuracy\"]\n",
        "        if accuracy >= self.threshold:\n",
        "            self.model.stop_training = True\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AWSadIFhoKc"
      },
      "source": [
        "callback = MyThresholdCallback(0.9)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zQYN3Q-wkgd",
        "outputId": "6159082b-8adb-4c17-a5d2-54a45d9246fc"
      },
      "source": [
        "model_history = model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy), callbacks=[callback], epochs = 1000)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.6499 - accuracy: 0.0149 - val_loss: 4.6662 - val_accuracy: 0.0065\n",
            "Epoch 2/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 4.6506 - accuracy: 0.0096 - val_loss: 4.6625 - val_accuracy: 0.0103\n",
            "Epoch 3/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.6406 - accuracy: 0.0147 - val_loss: 4.6535 - val_accuracy: 0.0121\n",
            "Epoch 4/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 4.6182 - accuracy: 0.0145 - val_loss: 4.6324 - val_accuracy: 0.0205\n",
            "Epoch 5/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.5864 - accuracy: 0.0194 - val_loss: 4.6192 - val_accuracy: 0.0280\n",
            "Epoch 6/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.5573 - accuracy: 0.0229 - val_loss: 4.5867 - val_accuracy: 0.0373\n",
            "Epoch 7/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.5310 - accuracy: 0.0255 - val_loss: 4.5567 - val_accuracy: 0.0439\n",
            "Epoch 8/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.5128 - accuracy: 0.0287 - val_loss: 4.5368 - val_accuracy: 0.0458\n",
            "Epoch 9/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.4942 - accuracy: 0.0320 - val_loss: 4.5055 - val_accuracy: 0.0551\n",
            "Epoch 10/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.4653 - accuracy: 0.0259 - val_loss: 4.4507 - val_accuracy: 0.0672\n",
            "Epoch 11/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.4443 - accuracy: 0.0374 - val_loss: 4.4115 - val_accuracy: 0.0672\n",
            "Epoch 12/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.4299 - accuracy: 0.0367 - val_loss: 4.3855 - val_accuracy: 0.0794\n",
            "Epoch 13/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 4.3892 - accuracy: 0.0425 - val_loss: 4.3321 - val_accuracy: 0.0906\n",
            "Epoch 14/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 4.3685 - accuracy: 0.0411 - val_loss: 4.3299 - val_accuracy: 0.0850\n",
            "Epoch 15/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 4.3479 - accuracy: 0.0470 - val_loss: 4.2778 - val_accuracy: 0.0812\n",
            "Epoch 16/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 4.3220 - accuracy: 0.0456 - val_loss: 4.2585 - val_accuracy: 0.0831\n",
            "Epoch 17/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 4.2957 - accuracy: 0.0533 - val_loss: 4.2167 - val_accuracy: 0.0840\n",
            "Epoch 18/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 4.2937 - accuracy: 0.0584 - val_loss: 4.1947 - val_accuracy: 0.1074\n",
            "Epoch 19/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.2560 - accuracy: 0.0544 - val_loss: 4.1486 - val_accuracy: 0.0980\n",
            "Epoch 20/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.2282 - accuracy: 0.0579 - val_loss: 4.0745 - val_accuracy: 0.1130\n",
            "Epoch 21/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 4.1858 - accuracy: 0.0670 - val_loss: 4.0753 - val_accuracy: 0.1083\n",
            "Epoch 22/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 4.1558 - accuracy: 0.0652 - val_loss: 4.0393 - val_accuracy: 0.1055\n",
            "Epoch 23/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.1244 - accuracy: 0.0661 - val_loss: 3.9487 - val_accuracy: 0.1317\n",
            "Epoch 24/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 4.1160 - accuracy: 0.0750 - val_loss: 3.9227 - val_accuracy: 0.1419\n",
            "Epoch 25/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.0624 - accuracy: 0.0825 - val_loss: 3.9065 - val_accuracy: 0.1475\n",
            "Epoch 26/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.0468 - accuracy: 0.0794 - val_loss: 3.8508 - val_accuracy: 0.1382\n",
            "Epoch 27/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 4.0265 - accuracy: 0.0827 - val_loss: 3.8104 - val_accuracy: 0.1597\n",
            "Epoch 28/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 4.0053 - accuracy: 0.0888 - val_loss: 3.8258 - val_accuracy: 0.1522\n",
            "Epoch 29/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 3.9634 - accuracy: 0.0899 - val_loss: 3.7511 - val_accuracy: 0.1821\n",
            "Epoch 30/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.9049 - accuracy: 0.1016 - val_loss: 3.6886 - val_accuracy: 0.1961\n",
            "Epoch 31/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.9375 - accuracy: 0.0904 - val_loss: 3.6684 - val_accuracy: 0.1933\n",
            "Epoch 32/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.8549 - accuracy: 0.1114 - val_loss: 3.6473 - val_accuracy: 0.2082\n",
            "Epoch 33/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.8182 - accuracy: 0.1091 - val_loss: 3.5478 - val_accuracy: 0.2129\n",
            "Epoch 34/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 3.8231 - accuracy: 0.1093 - val_loss: 3.5436 - val_accuracy: 0.2204\n",
            "Epoch 35/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.8086 - accuracy: 0.1063 - val_loss: 3.5045 - val_accuracy: 0.2129\n",
            "Epoch 36/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 3.7685 - accuracy: 0.1266 - val_loss: 3.4793 - val_accuracy: 0.2325\n",
            "Epoch 37/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.7452 - accuracy: 0.1294 - val_loss: 3.4613 - val_accuracy: 0.2232\n",
            "Epoch 38/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 3.6980 - accuracy: 0.1306 - val_loss: 3.3778 - val_accuracy: 0.2418\n",
            "Epoch 39/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 3.6843 - accuracy: 0.1310 - val_loss: 3.3485 - val_accuracy: 0.2409\n",
            "Epoch 40/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 3.6443 - accuracy: 0.1329 - val_loss: 3.3879 - val_accuracy: 0.2250\n",
            "Epoch 41/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.6221 - accuracy: 0.1427 - val_loss: 3.2838 - val_accuracy: 0.2456\n",
            "Epoch 42/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.6343 - accuracy: 0.1427 - val_loss: 3.2677 - val_accuracy: 0.2502\n",
            "Epoch 43/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.5879 - accuracy: 0.1542 - val_loss: 3.2844 - val_accuracy: 0.2502\n",
            "Epoch 44/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.5707 - accuracy: 0.1483 - val_loss: 3.2190 - val_accuracy: 0.2642\n",
            "Epoch 45/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.5074 - accuracy: 0.1544 - val_loss: 3.1298 - val_accuracy: 0.2913\n",
            "Epoch 46/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.5478 - accuracy: 0.1539 - val_loss: 3.1764 - val_accuracy: 0.2736\n",
            "Epoch 47/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.4873 - accuracy: 0.1668 - val_loss: 3.0929 - val_accuracy: 0.2820\n",
            "Epoch 48/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.4356 - accuracy: 0.1738 - val_loss: 3.0862 - val_accuracy: 0.3016\n",
            "Epoch 49/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 3.4387 - accuracy: 0.1649 - val_loss: 3.0495 - val_accuracy: 0.3016\n",
            "Epoch 50/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.3937 - accuracy: 0.1775 - val_loss: 2.9926 - val_accuracy: 0.3035\n",
            "Epoch 51/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 3.3764 - accuracy: 0.1831 - val_loss: 3.0027 - val_accuracy: 0.3081\n",
            "Epoch 52/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.3773 - accuracy: 0.1864 - val_loss: 2.9687 - val_accuracy: 0.3231\n",
            "Epoch 53/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 3.3532 - accuracy: 0.1955 - val_loss: 2.9255 - val_accuracy: 0.3315\n",
            "Epoch 54/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 3.3475 - accuracy: 0.1871 - val_loss: 2.9445 - val_accuracy: 0.3277\n",
            "Epoch 55/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.3112 - accuracy: 0.2025 - val_loss: 2.9275 - val_accuracy: 0.3203\n",
            "Epoch 56/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.3073 - accuracy: 0.1988 - val_loss: 2.8037 - val_accuracy: 0.3380\n",
            "Epoch 57/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.2626 - accuracy: 0.2030 - val_loss: 2.7951 - val_accuracy: 0.3455\n",
            "Epoch 58/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.2061 - accuracy: 0.2154 - val_loss: 2.7816 - val_accuracy: 0.3501\n",
            "Epoch 59/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.2306 - accuracy: 0.2053 - val_loss: 2.7752 - val_accuracy: 0.3595\n",
            "Epoch 60/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.2068 - accuracy: 0.2238 - val_loss: 2.7731 - val_accuracy: 0.3567\n",
            "Epoch 61/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.1588 - accuracy: 0.2217 - val_loss: 2.7631 - val_accuracy: 0.3501\n",
            "Epoch 62/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.1632 - accuracy: 0.2256 - val_loss: 2.7487 - val_accuracy: 0.3529\n",
            "Epoch 63/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.1368 - accuracy: 0.2221 - val_loss: 2.7187 - val_accuracy: 0.3567\n",
            "Epoch 64/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.1174 - accuracy: 0.2301 - val_loss: 2.7178 - val_accuracy: 0.3651\n",
            "Epoch 65/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.0747 - accuracy: 0.2390 - val_loss: 2.6654 - val_accuracy: 0.3716\n",
            "Epoch 66/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.0966 - accuracy: 0.2355 - val_loss: 2.6060 - val_accuracy: 0.3940\n",
            "Epoch 67/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.0796 - accuracy: 0.2359 - val_loss: 2.5884 - val_accuracy: 0.4006\n",
            "Epoch 68/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.0696 - accuracy: 0.2380 - val_loss: 2.6126 - val_accuracy: 0.3922\n",
            "Epoch 69/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 3.0168 - accuracy: 0.2539 - val_loss: 2.6265 - val_accuracy: 0.3828\n",
            "Epoch 70/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 3.0179 - accuracy: 0.2453 - val_loss: 2.5778 - val_accuracy: 0.3996\n",
            "Epoch 71/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.9609 - accuracy: 0.2586 - val_loss: 2.5123 - val_accuracy: 0.4099\n",
            "Epoch 72/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.9985 - accuracy: 0.2504 - val_loss: 2.5337 - val_accuracy: 0.3968\n",
            "Epoch 73/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.9754 - accuracy: 0.2532 - val_loss: 2.4725 - val_accuracy: 0.4080\n",
            "Epoch 74/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.9716 - accuracy: 0.2555 - val_loss: 2.5317 - val_accuracy: 0.3968\n",
            "Epoch 75/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 2.9150 - accuracy: 0.2717 - val_loss: 2.4538 - val_accuracy: 0.4118\n",
            "Epoch 76/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.9153 - accuracy: 0.2691 - val_loss: 2.4334 - val_accuracy: 0.4220\n",
            "Epoch 77/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 2.9032 - accuracy: 0.2728 - val_loss: 2.4265 - val_accuracy: 0.4174\n",
            "Epoch 78/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.9194 - accuracy: 0.2712 - val_loss: 2.5160 - val_accuracy: 0.3968\n",
            "Epoch 79/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.8862 - accuracy: 0.2803 - val_loss: 2.4286 - val_accuracy: 0.4276\n",
            "Epoch 80/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.8651 - accuracy: 0.2784 - val_loss: 2.4013 - val_accuracy: 0.4164\n",
            "Epoch 81/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.8099 - accuracy: 0.2885 - val_loss: 2.3616 - val_accuracy: 0.4304\n",
            "Epoch 82/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.8564 - accuracy: 0.2850 - val_loss: 2.3678 - val_accuracy: 0.4286\n",
            "Epoch 83/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 2.7939 - accuracy: 0.2922 - val_loss: 2.3922 - val_accuracy: 0.4080\n",
            "Epoch 84/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.8404 - accuracy: 0.2810 - val_loss: 2.3085 - val_accuracy: 0.4426\n",
            "Epoch 85/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.7736 - accuracy: 0.2995 - val_loss: 2.3166 - val_accuracy: 0.4472\n",
            "Epoch 86/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.7630 - accuracy: 0.2901 - val_loss: 2.2777 - val_accuracy: 0.4613\n",
            "Epoch 87/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.7825 - accuracy: 0.2941 - val_loss: 2.3429 - val_accuracy: 0.4174\n",
            "Epoch 88/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 2.7342 - accuracy: 0.3023 - val_loss: 2.2591 - val_accuracy: 0.4472\n",
            "Epoch 89/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.7219 - accuracy: 0.3041 - val_loss: 2.2635 - val_accuracy: 0.4351\n",
            "Epoch 90/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.7217 - accuracy: 0.3135 - val_loss: 2.2902 - val_accuracy: 0.4463\n",
            "Epoch 91/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.7155 - accuracy: 0.3111 - val_loss: 2.2717 - val_accuracy: 0.4500\n",
            "Epoch 92/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.6966 - accuracy: 0.3081 - val_loss: 2.1909 - val_accuracy: 0.4641\n",
            "Epoch 93/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.6679 - accuracy: 0.3170 - val_loss: 2.2338 - val_accuracy: 0.4491\n",
            "Epoch 94/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.6625 - accuracy: 0.3128 - val_loss: 2.2038 - val_accuracy: 0.4678\n",
            "Epoch 95/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.6623 - accuracy: 0.3153 - val_loss: 2.1837 - val_accuracy: 0.4631\n",
            "Epoch 96/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.6366 - accuracy: 0.3226 - val_loss: 2.1968 - val_accuracy: 0.4734\n",
            "Epoch 97/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 2.6281 - accuracy: 0.3217 - val_loss: 2.2211 - val_accuracy: 0.4585\n",
            "Epoch 98/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.5897 - accuracy: 0.3354 - val_loss: 2.1997 - val_accuracy: 0.4528\n",
            "Epoch 99/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 2.5837 - accuracy: 0.3495 - val_loss: 2.1895 - val_accuracy: 0.4566\n",
            "Epoch 100/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.6140 - accuracy: 0.3275 - val_loss: 2.1844 - val_accuracy: 0.4519\n",
            "Epoch 101/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.5549 - accuracy: 0.3438 - val_loss: 2.1409 - val_accuracy: 0.4641\n",
            "Epoch 102/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.5861 - accuracy: 0.3333 - val_loss: 2.1695 - val_accuracy: 0.4659\n",
            "Epoch 103/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.5637 - accuracy: 0.3422 - val_loss: 2.1338 - val_accuracy: 0.4790\n",
            "Epoch 104/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.5548 - accuracy: 0.3394 - val_loss: 2.1997 - val_accuracy: 0.4585\n",
            "Epoch 105/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.5194 - accuracy: 0.3406 - val_loss: 2.1345 - val_accuracy: 0.4538\n",
            "Epoch 106/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.5405 - accuracy: 0.3544 - val_loss: 2.1181 - val_accuracy: 0.4725\n",
            "Epoch 107/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.5029 - accuracy: 0.3597 - val_loss: 2.0695 - val_accuracy: 0.4809\n",
            "Epoch 108/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.5070 - accuracy: 0.3450 - val_loss: 2.0815 - val_accuracy: 0.4790\n",
            "Epoch 109/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.4966 - accuracy: 0.3483 - val_loss: 2.0832 - val_accuracy: 0.4734\n",
            "Epoch 110/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.4824 - accuracy: 0.3523 - val_loss: 2.1211 - val_accuracy: 0.4669\n",
            "Epoch 111/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.4765 - accuracy: 0.3502 - val_loss: 2.0691 - val_accuracy: 0.4734\n",
            "Epoch 112/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.4374 - accuracy: 0.3621 - val_loss: 2.1395 - val_accuracy: 0.4659\n",
            "Epoch 113/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.4679 - accuracy: 0.3527 - val_loss: 2.0263 - val_accuracy: 0.4893\n",
            "Epoch 114/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.4344 - accuracy: 0.3735 - val_loss: 2.1070 - val_accuracy: 0.4659\n",
            "Epoch 115/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.4464 - accuracy: 0.3560 - val_loss: 2.0448 - val_accuracy: 0.4781\n",
            "Epoch 116/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.3937 - accuracy: 0.3721 - val_loss: 2.0878 - val_accuracy: 0.4706\n",
            "Epoch 117/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.4160 - accuracy: 0.3649 - val_loss: 2.0770 - val_accuracy: 0.4725\n",
            "Epoch 118/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.4304 - accuracy: 0.3597 - val_loss: 2.0513 - val_accuracy: 0.4809\n",
            "Epoch 119/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.3887 - accuracy: 0.3770 - val_loss: 2.1392 - val_accuracy: 0.4631\n",
            "Epoch 120/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.3759 - accuracy: 0.3784 - val_loss: 2.0121 - val_accuracy: 0.4818\n",
            "Epoch 121/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.3959 - accuracy: 0.3721 - val_loss: 2.0505 - val_accuracy: 0.4734\n",
            "Epoch 122/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.3530 - accuracy: 0.3810 - val_loss: 2.0305 - val_accuracy: 0.4827\n",
            "Epoch 123/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 2.3526 - accuracy: 0.3801 - val_loss: 2.0194 - val_accuracy: 0.4706\n",
            "Epoch 124/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.3392 - accuracy: 0.3779 - val_loss: 2.0062 - val_accuracy: 0.4837\n",
            "Epoch 125/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.3141 - accuracy: 0.3829 - val_loss: 2.0486 - val_accuracy: 0.4743\n",
            "Epoch 126/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.3198 - accuracy: 0.3875 - val_loss: 2.0406 - val_accuracy: 0.4771\n",
            "Epoch 127/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 2.3232 - accuracy: 0.3847 - val_loss: 2.0067 - val_accuracy: 0.4865\n",
            "Epoch 128/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.3081 - accuracy: 0.3941 - val_loss: 2.0278 - val_accuracy: 0.4799\n",
            "Epoch 129/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.3195 - accuracy: 0.3791 - val_loss: 1.9953 - val_accuracy: 0.4799\n",
            "Epoch 130/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.2654 - accuracy: 0.3994 - val_loss: 1.9845 - val_accuracy: 0.4846\n",
            "Epoch 131/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.2927 - accuracy: 0.3826 - val_loss: 2.0036 - val_accuracy: 0.4771\n",
            "Epoch 132/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 2.2636 - accuracy: 0.4018 - val_loss: 1.9714 - val_accuracy: 0.4930\n",
            "Epoch 133/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.2623 - accuracy: 0.3878 - val_loss: 1.9265 - val_accuracy: 0.4986\n",
            "Epoch 134/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.2623 - accuracy: 0.4015 - val_loss: 1.9709 - val_accuracy: 0.5070\n",
            "Epoch 135/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.2653 - accuracy: 0.4027 - val_loss: 1.9517 - val_accuracy: 0.5126\n",
            "Epoch 136/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.2457 - accuracy: 0.4020 - val_loss: 1.9531 - val_accuracy: 0.4995\n",
            "Epoch 137/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.2431 - accuracy: 0.4078 - val_loss: 1.9362 - val_accuracy: 0.5061\n",
            "Epoch 138/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.2351 - accuracy: 0.4081 - val_loss: 1.9330 - val_accuracy: 0.4995\n",
            "Epoch 139/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 2.1982 - accuracy: 0.4221 - val_loss: 1.8694 - val_accuracy: 0.5238\n",
            "Epoch 140/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.1621 - accuracy: 0.4188 - val_loss: 1.9585 - val_accuracy: 0.5014\n",
            "Epoch 141/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.2063 - accuracy: 0.4104 - val_loss: 1.9219 - val_accuracy: 0.5117\n",
            "Epoch 142/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.1663 - accuracy: 0.4146 - val_loss: 1.9462 - val_accuracy: 0.5005\n",
            "Epoch 143/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.1900 - accuracy: 0.4170 - val_loss: 1.8950 - val_accuracy: 0.5163\n",
            "Epoch 144/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.1810 - accuracy: 0.4022 - val_loss: 1.8923 - val_accuracy: 0.5117\n",
            "Epoch 145/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.1792 - accuracy: 0.4121 - val_loss: 1.9282 - val_accuracy: 0.5098\n",
            "Epoch 146/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.1551 - accuracy: 0.4135 - val_loss: 1.9256 - val_accuracy: 0.5023\n",
            "Epoch 147/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.1474 - accuracy: 0.4186 - val_loss: 1.9452 - val_accuracy: 0.5033\n",
            "Epoch 148/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.1700 - accuracy: 0.4160 - val_loss: 1.9586 - val_accuracy: 0.4967\n",
            "Epoch 149/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.1458 - accuracy: 0.4132 - val_loss: 1.9391 - val_accuracy: 0.4958\n",
            "Epoch 150/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.1257 - accuracy: 0.4296 - val_loss: 1.9380 - val_accuracy: 0.4958\n",
            "Epoch 151/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.1186 - accuracy: 0.4298 - val_loss: 1.9436 - val_accuracy: 0.5098\n",
            "Epoch 152/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.0882 - accuracy: 0.4342 - val_loss: 1.8470 - val_accuracy: 0.5303\n",
            "Epoch 153/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.0859 - accuracy: 0.4258 - val_loss: 1.9055 - val_accuracy: 0.5051\n",
            "Epoch 154/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.1104 - accuracy: 0.4286 - val_loss: 1.8427 - val_accuracy: 0.5275\n",
            "Epoch 155/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.0631 - accuracy: 0.4408 - val_loss: 1.8578 - val_accuracy: 0.5331\n",
            "Epoch 156/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.0963 - accuracy: 0.4303 - val_loss: 1.8470 - val_accuracy: 0.5257\n",
            "Epoch 157/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.0472 - accuracy: 0.4443 - val_loss: 1.8458 - val_accuracy: 0.5229\n",
            "Epoch 158/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 2.0825 - accuracy: 0.4380 - val_loss: 1.8224 - val_accuracy: 0.5331\n",
            "Epoch 159/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.0379 - accuracy: 0.4518 - val_loss: 1.8826 - val_accuracy: 0.5163\n",
            "Epoch 160/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.0390 - accuracy: 0.4506 - val_loss: 1.8627 - val_accuracy: 0.5238\n",
            "Epoch 161/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.0859 - accuracy: 0.4363 - val_loss: 1.8852 - val_accuracy: 0.5163\n",
            "Epoch 162/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 2.0344 - accuracy: 0.4455 - val_loss: 1.8951 - val_accuracy: 0.5126\n",
            "Epoch 163/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.0378 - accuracy: 0.4457 - val_loss: 1.8608 - val_accuracy: 0.5210\n",
            "Epoch 164/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.0244 - accuracy: 0.4478 - val_loss: 1.8675 - val_accuracy: 0.5229\n",
            "Epoch 165/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 2.0530 - accuracy: 0.4469 - val_loss: 1.8575 - val_accuracy: 0.5294\n",
            "Epoch 166/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.0274 - accuracy: 0.4429 - val_loss: 1.8706 - val_accuracy: 0.5210\n",
            "Epoch 167/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.0098 - accuracy: 0.4511 - val_loss: 1.8528 - val_accuracy: 0.5191\n",
            "Epoch 168/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 2.0004 - accuracy: 0.4506 - val_loss: 1.8452 - val_accuracy: 0.5331\n",
            "Epoch 169/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.9844 - accuracy: 0.4609 - val_loss: 1.8546 - val_accuracy: 0.5303\n",
            "Epoch 170/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.9624 - accuracy: 0.4557 - val_loss: 1.8715 - val_accuracy: 0.5135\n",
            "Epoch 171/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 2.0013 - accuracy: 0.4527 - val_loss: 1.8248 - val_accuracy: 0.5303\n",
            "Epoch 172/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 1.9642 - accuracy: 0.4529 - val_loss: 1.8448 - val_accuracy: 0.5247\n",
            "Epoch 173/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.9786 - accuracy: 0.4695 - val_loss: 1.8538 - val_accuracy: 0.5219\n",
            "Epoch 174/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.9709 - accuracy: 0.4618 - val_loss: 1.7957 - val_accuracy: 0.5331\n",
            "Epoch 175/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.9411 - accuracy: 0.4672 - val_loss: 1.8596 - val_accuracy: 0.5257\n",
            "Epoch 176/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.9627 - accuracy: 0.4578 - val_loss: 1.8637 - val_accuracy: 0.5229\n",
            "Epoch 177/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.9367 - accuracy: 0.4683 - val_loss: 1.8139 - val_accuracy: 0.5444\n",
            "Epoch 178/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.9221 - accuracy: 0.4698 - val_loss: 1.8371 - val_accuracy: 0.5313\n",
            "Epoch 179/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.9127 - accuracy: 0.4707 - val_loss: 1.8187 - val_accuracy: 0.5397\n",
            "Epoch 180/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.9250 - accuracy: 0.4754 - val_loss: 1.8553 - val_accuracy: 0.5378\n",
            "Epoch 181/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.9136 - accuracy: 0.4805 - val_loss: 1.8470 - val_accuracy: 0.5257\n",
            "Epoch 182/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.9198 - accuracy: 0.4698 - val_loss: 1.7743 - val_accuracy: 0.5434\n",
            "Epoch 183/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 1.9021 - accuracy: 0.4751 - val_loss: 1.8498 - val_accuracy: 0.5229\n",
            "Epoch 184/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.9036 - accuracy: 0.4740 - val_loss: 1.8127 - val_accuracy: 0.5378\n",
            "Epoch 185/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.9053 - accuracy: 0.4845 - val_loss: 1.8329 - val_accuracy: 0.5247\n",
            "Epoch 186/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.9057 - accuracy: 0.4712 - val_loss: 1.8142 - val_accuracy: 0.5406\n",
            "Epoch 187/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.8815 - accuracy: 0.4833 - val_loss: 1.8140 - val_accuracy: 0.5322\n",
            "Epoch 188/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.9100 - accuracy: 0.4793 - val_loss: 1.8072 - val_accuracy: 0.5331\n",
            "Epoch 189/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.8837 - accuracy: 0.4749 - val_loss: 1.7631 - val_accuracy: 0.5434\n",
            "Epoch 190/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.8827 - accuracy: 0.4782 - val_loss: 1.8339 - val_accuracy: 0.5210\n",
            "Epoch 191/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.8496 - accuracy: 0.4917 - val_loss: 1.8399 - val_accuracy: 0.5322\n",
            "Epoch 192/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 1.8711 - accuracy: 0.4814 - val_loss: 1.7886 - val_accuracy: 0.5453\n",
            "Epoch 193/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.8683 - accuracy: 0.4854 - val_loss: 1.8075 - val_accuracy: 0.5425\n",
            "Epoch 194/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.8476 - accuracy: 0.4882 - val_loss: 1.8026 - val_accuracy: 0.5528\n",
            "Epoch 195/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.8449 - accuracy: 0.4922 - val_loss: 1.7898 - val_accuracy: 0.5453\n",
            "Epoch 196/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.8772 - accuracy: 0.4784 - val_loss: 1.7603 - val_accuracy: 0.5425\n",
            "Epoch 197/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.8200 - accuracy: 0.4863 - val_loss: 1.7873 - val_accuracy: 0.5406\n",
            "Epoch 198/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.8270 - accuracy: 0.4966 - val_loss: 1.7953 - val_accuracy: 0.5369\n",
            "Epoch 199/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.8151 - accuracy: 0.4999 - val_loss: 1.8192 - val_accuracy: 0.5387\n",
            "Epoch 200/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.8111 - accuracy: 0.5018 - val_loss: 1.7450 - val_accuracy: 0.5528\n",
            "Epoch 201/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.8054 - accuracy: 0.4966 - val_loss: 1.8434 - val_accuracy: 0.5387\n",
            "Epoch 202/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.7879 - accuracy: 0.5022 - val_loss: 1.8503 - val_accuracy: 0.5294\n",
            "Epoch 203/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.7797 - accuracy: 0.4947 - val_loss: 1.8285 - val_accuracy: 0.5425\n",
            "Epoch 204/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.7889 - accuracy: 0.5043 - val_loss: 1.7945 - val_accuracy: 0.5378\n",
            "Epoch 205/1000\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 1.7941 - accuracy: 0.5036 - val_loss: 1.7858 - val_accuracy: 0.5453\n",
            "Epoch 206/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.7812 - accuracy: 0.4982 - val_loss: 1.7597 - val_accuracy: 0.5565\n",
            "Epoch 207/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.7722 - accuracy: 0.5018 - val_loss: 1.7513 - val_accuracy: 0.5584\n",
            "Epoch 208/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.7798 - accuracy: 0.4980 - val_loss: 1.7255 - val_accuracy: 0.5621\n",
            "Epoch 209/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.7591 - accuracy: 0.5006 - val_loss: 1.7720 - val_accuracy: 0.5472\n",
            "Epoch 210/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.7166 - accuracy: 0.5172 - val_loss: 1.7730 - val_accuracy: 0.5556\n",
            "Epoch 211/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.7592 - accuracy: 0.5097 - val_loss: 1.7879 - val_accuracy: 0.5537\n",
            "Epoch 212/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.7375 - accuracy: 0.5127 - val_loss: 1.7728 - val_accuracy: 0.5425\n",
            "Epoch 213/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.7621 - accuracy: 0.5050 - val_loss: 1.7363 - val_accuracy: 0.5621\n",
            "Epoch 214/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.7580 - accuracy: 0.5109 - val_loss: 1.7840 - val_accuracy: 0.5621\n",
            "Epoch 215/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.7189 - accuracy: 0.5060 - val_loss: 1.7639 - val_accuracy: 0.5546\n",
            "Epoch 216/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.7015 - accuracy: 0.5181 - val_loss: 1.7761 - val_accuracy: 0.5621\n",
            "Epoch 217/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.7313 - accuracy: 0.5221 - val_loss: 1.7864 - val_accuracy: 0.5462\n",
            "Epoch 218/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.7491 - accuracy: 0.5104 - val_loss: 1.7108 - val_accuracy: 0.5593\n",
            "Epoch 219/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.7206 - accuracy: 0.5106 - val_loss: 1.7790 - val_accuracy: 0.5668\n",
            "Epoch 220/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.7100 - accuracy: 0.5193 - val_loss: 1.8143 - val_accuracy: 0.5537\n",
            "Epoch 221/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.7235 - accuracy: 0.5176 - val_loss: 1.8060 - val_accuracy: 0.5518\n",
            "Epoch 222/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.6879 - accuracy: 0.5153 - val_loss: 1.7890 - val_accuracy: 0.5584\n",
            "Epoch 223/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.6882 - accuracy: 0.5265 - val_loss: 1.7343 - val_accuracy: 0.5649\n",
            "Epoch 224/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.7030 - accuracy: 0.5225 - val_loss: 1.8186 - val_accuracy: 0.5584\n",
            "Epoch 225/1000\n",
            "134/134 [==============================] - 15s 110ms/step - loss: 1.7065 - accuracy: 0.5144 - val_loss: 1.7545 - val_accuracy: 0.5649\n",
            "Epoch 226/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.6982 - accuracy: 0.5216 - val_loss: 1.7604 - val_accuracy: 0.5649\n",
            "Epoch 227/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.6446 - accuracy: 0.5312 - val_loss: 1.7312 - val_accuracy: 0.5668\n",
            "Epoch 228/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.6604 - accuracy: 0.5277 - val_loss: 1.7492 - val_accuracy: 0.5658\n",
            "Epoch 229/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.6656 - accuracy: 0.5223 - val_loss: 1.7112 - val_accuracy: 0.5696\n",
            "Epoch 230/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.6487 - accuracy: 0.5349 - val_loss: 1.7493 - val_accuracy: 0.5668\n",
            "Epoch 231/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.6714 - accuracy: 0.5293 - val_loss: 1.7340 - val_accuracy: 0.5696\n",
            "Epoch 232/1000\n",
            "134/134 [==============================] - 15s 115ms/step - loss: 1.6723 - accuracy: 0.5326 - val_loss: 1.7195 - val_accuracy: 0.5752\n",
            "Epoch 233/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.6702 - accuracy: 0.5288 - val_loss: 1.7643 - val_accuracy: 0.5630\n",
            "Epoch 234/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.6175 - accuracy: 0.5363 - val_loss: 1.7909 - val_accuracy: 0.5677\n",
            "Epoch 235/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.6208 - accuracy: 0.5377 - val_loss: 1.8062 - val_accuracy: 0.5630\n",
            "Epoch 236/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.6828 - accuracy: 0.5244 - val_loss: 1.7942 - val_accuracy: 0.5658\n",
            "Epoch 237/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.6461 - accuracy: 0.5305 - val_loss: 1.7825 - val_accuracy: 0.5630\n",
            "Epoch 238/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.6493 - accuracy: 0.5375 - val_loss: 1.7379 - val_accuracy: 0.5649\n",
            "Epoch 239/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.5900 - accuracy: 0.5487 - val_loss: 1.7737 - val_accuracy: 0.5686\n",
            "Epoch 240/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.6461 - accuracy: 0.5317 - val_loss: 1.7791 - val_accuracy: 0.5630\n",
            "Epoch 241/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.6110 - accuracy: 0.5422 - val_loss: 1.7777 - val_accuracy: 0.5602\n",
            "Epoch 242/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.6143 - accuracy: 0.5417 - val_loss: 1.7519 - val_accuracy: 0.5705\n",
            "Epoch 243/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.6331 - accuracy: 0.5382 - val_loss: 1.8091 - val_accuracy: 0.5574\n",
            "Epoch 244/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.5549 - accuracy: 0.5578 - val_loss: 1.7774 - val_accuracy: 0.5528\n",
            "Epoch 245/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.5829 - accuracy: 0.5485 - val_loss: 1.7501 - val_accuracy: 0.5677\n",
            "Epoch 246/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.5846 - accuracy: 0.5534 - val_loss: 1.7194 - val_accuracy: 0.5742\n",
            "Epoch 247/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.6003 - accuracy: 0.5422 - val_loss: 1.7504 - val_accuracy: 0.5686\n",
            "Epoch 248/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.6180 - accuracy: 0.5447 - val_loss: 1.7242 - val_accuracy: 0.5686\n",
            "Epoch 249/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.6052 - accuracy: 0.5417 - val_loss: 1.7358 - val_accuracy: 0.5817\n",
            "Epoch 250/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.5864 - accuracy: 0.5426 - val_loss: 1.7919 - val_accuracy: 0.5658\n",
            "Epoch 251/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.6062 - accuracy: 0.5398 - val_loss: 1.7556 - val_accuracy: 0.5677\n",
            "Epoch 252/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.5761 - accuracy: 0.5573 - val_loss: 1.7543 - val_accuracy: 0.5742\n",
            "Epoch 253/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.5594 - accuracy: 0.5601 - val_loss: 1.7233 - val_accuracy: 0.5817\n",
            "Epoch 254/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.5788 - accuracy: 0.5501 - val_loss: 1.7225 - val_accuracy: 0.5724\n",
            "Epoch 255/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.5465 - accuracy: 0.5550 - val_loss: 1.6861 - val_accuracy: 0.5808\n",
            "Epoch 256/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.5688 - accuracy: 0.5580 - val_loss: 1.7098 - val_accuracy: 0.5798\n",
            "Epoch 257/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.5497 - accuracy: 0.5475 - val_loss: 1.7212 - val_accuracy: 0.5826\n",
            "Epoch 258/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.5639 - accuracy: 0.5604 - val_loss: 1.7644 - val_accuracy: 0.5724\n",
            "Epoch 259/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.5502 - accuracy: 0.5559 - val_loss: 1.7594 - val_accuracy: 0.5686\n",
            "Epoch 260/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.5300 - accuracy: 0.5592 - val_loss: 1.7760 - val_accuracy: 0.5705\n",
            "Epoch 261/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.5635 - accuracy: 0.5538 - val_loss: 1.7394 - val_accuracy: 0.5733\n",
            "Epoch 262/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.5227 - accuracy: 0.5552 - val_loss: 1.7487 - val_accuracy: 0.5733\n",
            "Epoch 263/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.5107 - accuracy: 0.5601 - val_loss: 1.7813 - val_accuracy: 0.5640\n",
            "Epoch 264/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.5412 - accuracy: 0.5541 - val_loss: 1.6914 - val_accuracy: 0.5864\n",
            "Epoch 265/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.5382 - accuracy: 0.5550 - val_loss: 1.7312 - val_accuracy: 0.5733\n",
            "Epoch 266/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.5058 - accuracy: 0.5630 - val_loss: 1.7510 - val_accuracy: 0.5808\n",
            "Epoch 267/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.5150 - accuracy: 0.5625 - val_loss: 1.7753 - val_accuracy: 0.5798\n",
            "Epoch 268/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.5045 - accuracy: 0.5646 - val_loss: 1.7286 - val_accuracy: 0.5854\n",
            "Epoch 269/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.4774 - accuracy: 0.5758 - val_loss: 1.7417 - val_accuracy: 0.5770\n",
            "Epoch 270/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.5163 - accuracy: 0.5580 - val_loss: 1.7468 - val_accuracy: 0.5696\n",
            "Epoch 271/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.5118 - accuracy: 0.5597 - val_loss: 1.7315 - val_accuracy: 0.5696\n",
            "Epoch 272/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.4847 - accuracy: 0.5704 - val_loss: 1.7598 - val_accuracy: 0.5761\n",
            "Epoch 273/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.4869 - accuracy: 0.5639 - val_loss: 1.7720 - val_accuracy: 0.5724\n",
            "Epoch 274/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.4829 - accuracy: 0.5634 - val_loss: 1.6937 - val_accuracy: 0.5929\n",
            "Epoch 275/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.4922 - accuracy: 0.5751 - val_loss: 1.7510 - val_accuracy: 0.5798\n",
            "Epoch 276/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.4938 - accuracy: 0.5653 - val_loss: 1.7275 - val_accuracy: 0.5892\n",
            "Epoch 277/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.5061 - accuracy: 0.5672 - val_loss: 1.7387 - val_accuracy: 0.5808\n",
            "Epoch 278/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.4816 - accuracy: 0.5770 - val_loss: 1.6999 - val_accuracy: 0.5892\n",
            "Epoch 279/1000\n",
            "134/134 [==============================] - 15s 115ms/step - loss: 1.4713 - accuracy: 0.5728 - val_loss: 1.7329 - val_accuracy: 0.5873\n",
            "Epoch 280/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.4953 - accuracy: 0.5660 - val_loss: 1.7436 - val_accuracy: 0.5817\n",
            "Epoch 281/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.4594 - accuracy: 0.5744 - val_loss: 1.7378 - val_accuracy: 0.5798\n",
            "Epoch 282/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.4562 - accuracy: 0.5728 - val_loss: 1.7422 - val_accuracy: 0.5836\n",
            "Epoch 283/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.4278 - accuracy: 0.5840 - val_loss: 1.8089 - val_accuracy: 0.5658\n",
            "Epoch 284/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.4428 - accuracy: 0.5802 - val_loss: 1.7552 - val_accuracy: 0.5826\n",
            "Epoch 285/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.4465 - accuracy: 0.5721 - val_loss: 1.7671 - val_accuracy: 0.5752\n",
            "Epoch 286/1000\n",
            "134/134 [==============================] - 15s 111ms/step - loss: 1.3986 - accuracy: 0.5971 - val_loss: 1.7764 - val_accuracy: 0.5826\n",
            "Epoch 287/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.4485 - accuracy: 0.5746 - val_loss: 1.7893 - val_accuracy: 0.5696\n",
            "Epoch 288/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.4518 - accuracy: 0.5847 - val_loss: 1.7392 - val_accuracy: 0.5873\n",
            "Epoch 289/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.4289 - accuracy: 0.5795 - val_loss: 1.6918 - val_accuracy: 0.5929\n",
            "Epoch 290/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.4258 - accuracy: 0.5950 - val_loss: 1.7105 - val_accuracy: 0.5873\n",
            "Epoch 291/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.4319 - accuracy: 0.5814 - val_loss: 1.7747 - val_accuracy: 0.5696\n",
            "Epoch 292/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.4486 - accuracy: 0.5751 - val_loss: 1.7460 - val_accuracy: 0.5798\n",
            "Epoch 293/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.4268 - accuracy: 0.5910 - val_loss: 1.7851 - val_accuracy: 0.5798\n",
            "Epoch 294/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.4593 - accuracy: 0.5786 - val_loss: 1.7034 - val_accuracy: 0.5901\n",
            "Epoch 295/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.4099 - accuracy: 0.5933 - val_loss: 1.7880 - val_accuracy: 0.5808\n",
            "Epoch 296/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.3622 - accuracy: 0.5945 - val_loss: 1.7478 - val_accuracy: 0.5817\n",
            "Epoch 297/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.4252 - accuracy: 0.5798 - val_loss: 1.7496 - val_accuracy: 0.5789\n",
            "Epoch 298/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.3894 - accuracy: 0.5905 - val_loss: 1.7486 - val_accuracy: 0.5966\n",
            "Epoch 299/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.3962 - accuracy: 0.5971 - val_loss: 1.7247 - val_accuracy: 0.5948\n",
            "Epoch 300/1000\n",
            "134/134 [==============================] - 15s 114ms/step - loss: 1.3981 - accuracy: 0.5856 - val_loss: 1.7256 - val_accuracy: 0.5938\n",
            "Epoch 301/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.3933 - accuracy: 0.5910 - val_loss: 1.7475 - val_accuracy: 0.5957\n",
            "Epoch 302/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.3669 - accuracy: 0.5947 - val_loss: 1.7532 - val_accuracy: 0.5901\n",
            "Epoch 303/1000\n",
            "134/134 [==============================] - 15s 112ms/step - loss: 1.3982 - accuracy: 0.5898 - val_loss: 1.7315 - val_accuracy: 0.5966\n",
            "Epoch 304/1000\n",
            "134/134 [==============================] - 15s 113ms/step - loss: 1.3766 - accuracy: 0.5971 - val_loss: 1.7154 - val_accuracy: 0.6088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNOXVsOGystf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d8132a5-73f5-4226-c6d6-62cf93562f93"
      },
      "source": [
        "model.evaluate(testx,testy)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 0s 7ms/step - loss: 1.7154 - accuracy: 0.6088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.715355396270752, 0.608776867389679]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LulUWkmS3BCg"
      },
      "source": [
        "#PREDICTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dre5yuFu3NHR"
      },
      "source": [
        "Val = []\n",
        "for i in range(len(labels)):\n",
        "  Val.append(i)\n",
        "\n",
        "reverse_mapping=dict(zip(Val,labels)) "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6qbmTRk2P72"
      },
      "source": [
        "image=load_img(\"/content/drive/MyDrive/DATASETS/YogaDataset/poseDataset/agnistambhasana/61-0.png\",target_size=(128,128))\n",
        "\n",
        "image=img_to_array(image) \n",
        "image=image/255.0\n",
        "prediction_image=np.array(image)\n",
        "prediction_image= np.expand_dims(image, axis=0)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LETBq0BI2fuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d76fc97-fe66-4d24-8801-47dfbb1947a5"
      },
      "source": [
        "prediction=model.predict(prediction_image)\n",
        "value=np.argmax(prediction)\n",
        "move_name = reverse_mapping[value]\n",
        "print(\"Prediction is {}.\".format(move_name))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction is agnistambhasana.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU_LwB0R6Wyo"
      },
      "source": [
        "model.save('/content/drive/MyDrive/model/try.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}